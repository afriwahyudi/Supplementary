{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing the required library\n",
    "!pip install tensorflow==2.10.0\n",
    "!pip install numpy==1.23.4\n",
    "!pip install pandas==1.5.2\n",
    "!pip install scikit-learn==1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing and visualizationlibrary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "# Tensorflow and keras library\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.models import load_model\n",
    "# ScikitLearn library\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# Misc\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from unicodedata import name\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"To ensure repeatability, use the following setup:\")\n",
    "print(\"TensorFlow version:\", \"2.10.0\")\n",
    "print(\"Numpy version:\", '1.23.4')\n",
    "print(\"Pandas version:\", '1.5.2')\n",
    "print(\"SKLearn version:\", \"1.1.3\")\n",
    "print(\"Python version:\", \"3.8.6 (tags/v3.8.6:db45529, Sep 23 2020, 15:52:53) [MSC v.1927 64 bit (AMD64)]\")\n",
    "print(\"==============================\")\n",
    "print(\"Your current library version:\")\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"SKLearn version:\", sklearn.__version__)\n",
    "print(\"Python version:\",sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset from GitHub repo\n",
    "csv_path1 = 'https://raw.githubusercontent.com/afriwahyudi/Supplementary/main/datasetscsv/trainval_set.csv' #Training-validation datasets\n",
    "csv_path2 = 'https://raw.githubusercontent.com/afriwahyudi/Supplementary/main/datasetscsv/test_set.csv' #Unseen test set\n",
    "csv_path3 = 'https://raw.githubusercontent.com/afriwahyudi/Supplementary/main/datasetscsv/trainval_set.csv' #Combined train-validation-test set\n",
    "csv_path4 = 'https://raw.githubusercontent.com/afriwahyudi/Supplementary/main/datasetscsv/allMolecule.csv' #Molecule only set\n",
    "seed = 21\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing models from GitHub repo in '/Model' folder\n",
    "!wget https://github.com/afriwahyudi/Supplementary/raw/main/Model/SWISH_WnD.h5\n",
    "!wget https://github.com/afriwahyudi/Supplementary/raw/main/Model/SWISH_SQ.h5\n",
    "!wget https://github.com/afriwahyudi/Supplementary/raw/main/Model/ReLU_WnD.h5\n",
    "!wget https://github.com/afriwahyudi/Supplementary/raw/main/Model/ReLU_SQ.h5\n",
    "!wget https://github.com/afriwahyudi/Supplementary/raw/main/Model/sigmoid_WnD.h5\n",
    "!wget https://github.com/afriwahyudi/Supplementary/raw/main/Model/sigmoid_SQ.h5\n",
    "!wget https://github.com/afriwahyudi/Supplementary/raw/main/Model/tanh_WnD.h5\n",
    "!wget https://github.com/afriwahyudi/Supplementary/raw/main/Model/tanh_SQ.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "trainval_df = pd.read_csv(csv_path1, names=[\"Molecule\", \"Formula\",\"SMILES\",\"Type\",\"Cyclicity\",\n",
    "                                       \"Primary counts\",\"Secondary counts\",\"Tertiary counts\",\n",
    "                                       \"Hydroxyl counts\",\"Carboxyl counts\",\"Oxyl counts\",\n",
    "                                       \"M0(nhb)\", \"M0(oh)\", \"M0(nh)\", \"M0(op)\", \n",
    "                                       \"M1(nhb_donor)\", \"M1(nhb_weak)\", \"M1(nhb_acceptor)\",\n",
    "                                       \"M1(oh_donor)\", \"M1(oh_weak)\",\"M1(oh_acceptor)\",\n",
    "                                       \"M1(nh_donor)\", \"M1(nh_weak)\", \"M1(nh_acceptor)\",\n",
    "                                       \"M1(op_donor)\", \"M1(op_weak)\", \"M1(op_acceptor)\",\n",
    "                                       \"M2(nhb)\", \"M2(oh)\", \"M2(nh)\",\"M2(op)\",\n",
    "                                       \"MW\",\"Partial Pressure\",\"Temperature\",\n",
    "                                       \"Amine Concentration\", \"Absorption Capacity\", \"References\",\"Rounded Concentration\", \"Abbreviation\"]) \n",
    "test_df     = pd.read_csv(csv_path2, names=[\"Molecule\", \"Formula\",\"SMILES\",\"Type\",\"Cyclicity\", \n",
    "                                       \"Primary counts\",\"Secondary counts\",\"Tertiary counts\",\n",
    "                                       \"Hydroxyl counts\",\"Carboxyl counts\",\"Oxyl counts\",\n",
    "                                       \"M0(nhb)\", \"M0(oh)\", \"M0(nh)\", \"M0(op)\", \n",
    "                                       \"M1(nhb_donor)\", \"M1(nhb_weak)\", \"M1(nhb_acceptor)\",\n",
    "                                       \"M1(oh_donor)\", \"M1(oh_weak)\",\"M1(oh_acceptor)\",\n",
    "                                       \"M1(nh_donor)\", \"M1(nh_weak)\", \"M1(nh_acceptor)\",\n",
    "                                       \"M1(op_donor)\", \"M1(op_weak)\", \"M1(op_acceptor)\",\n",
    "                                       \"M2(nhb)\", \"M2(oh)\", \"M2(nh)\",\"M2(op)\",\n",
    "                                       \"MW\",\"Partial Pressure\",\"Temperature\",\n",
    "                                       \"Amine Concentration\", \"Absorption Capacity\", \"References\",\"Rounded Concentration\", \"Abbreviation\"]) \n",
    "# PREPROCESSING\n",
    "X_test_label = test_df.drop(columns=[\"Absorption Capacity\"])\n",
    "y_test = test_df['Absorption Capacity']\n",
    "\n",
    "X_trainval_label =  trainval_df.drop(columns=[\"Absorption Capacity\"])\n",
    "y_trainval_label = trainval_df['Absorption Capacity']\n",
    "\n",
    "# DATA SPLITING\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval_label, y_trainval_label, test_size=0.20, random_state=seed)\n",
    "\n",
    "# Reserve the dataset for visualization\n",
    "X_train_1 = X_train.copy()\n",
    "X_val_1 = X_val.copy()\n",
    "X_reserved = pd.concat([X_train_1, X_val_1, X_test_label], axis=0)\n",
    "\n",
    "# DROPPING STRINGS AND DATA PREPROCESSING\n",
    "X_train = X_train.drop(columns=[\"Molecule\", \"Formula\", \"SMILES\", \"Type\", \"Cyclicity\", \"References\", \"Rounded Concentration\", \"Abbreviation\"])\n",
    "X_test = X_test_label.drop(columns=[\"Molecule\", \"Formula\", \"SMILES\", \"Type\", \"Cyclicity\", \"References\", \"Rounded Concentration\", \"Abbreviation\"])\n",
    "X_val = X_val.drop(columns=[\"Molecule\", \"Formula\", \"SMILES\", \"Type\", \"Cyclicity\", \"References\", \"Rounded Concentration\", \"Abbreviation\"])\n",
    "\n",
    "feature_names = X_train.columns.tolist()\n",
    "preprocessor = Pipeline(steps=[('step1', StandardScaler())])\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=feature_names)\n",
    "\n",
    "X_val = pipeline.transform(X_val)\n",
    "X_val = pd.DataFrame(X_val, columns=feature_names)\n",
    "\n",
    "X_test = pipeline.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=feature_names)\n",
    "\n",
    "master_df = pd.read_csv(csv_path3, \n",
    "    names=[\"Molecule\",\"Formula\",\"SMILES\",\"Type\",\"Cyclicity\",\n",
    "           \"Primary counts\",\"Secondary counts\",\"Tertiary counts\",\n",
    "           \"Hydroxyl counts\",\"Carboxyl counts\",\"Oxyl counts\",\n",
    "           \"M0(nhb)\", \"M0(oh)\", \"M0(nh)\", \"M0(op)\", \n",
    "           \"M1(nhb_donor)\", \"M1(nhb_weak)\", \"M1(nhb_acceptor)\",\n",
    "           \"M1(oh_donor)\", \"M1(oh_weak)\",\"M1(oh_acceptor)\",\n",
    "           \"M1(nh_donor)\", \"M1(nh_weak)\", \"M1(nh_acceptor)\",\n",
    "           \"M1(op_donor)\", \"M1(op_weak)\", \"M1(op_acceptor)\",\n",
    "           \"M2(nhb)\", \"M2(oh)\", \"M2(nh)\",\"M2(op)\",\n",
    "           \"MW\",\"Partial Pressure\",\"Temperature\",\n",
    "           \"Amine Concentration\", \"Absorption Capacity\", \"References\",\"Rounded Concentration\",\"Abbreviation\"]) \n",
    "scaler = preprocessor.named_steps['step1']\n",
    "mean_values = scaler.mean_[27] # mean pressure\n",
    "std_values = scaler.scale_[27] # std pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL IMPORT\n",
    "model_path = ['SWISH_WnD.h5',\n",
    "              'SWISH_SQ.h5',\n",
    "              'ReLU_WnD.h5',\n",
    "              'ReLU_SQ.h5',\n",
    "              'sigmoid_WnD.h5',\n",
    "              'sigmoid_SQ.h5',\n",
    "              'tanh_WnD.h5',\n",
    "              'tanh_SQ.h5']\n",
    "RMSE = []\n",
    "MAE  = []\n",
    "R2 = []\n",
    "for i in range(len(model_path)):\n",
    "    model = load_model(model_path[i])\n",
    "    y_train_pred    = model.predict(X_train)\n",
    "    RSME_train      = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    MAE_train       = mean_absolute_error(y_train, y_train_pred)\n",
    "    R2_train        = r2_score(y_train, y_train_pred)*100\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    RMSE_val        = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    MAE_val         = mean_absolute_error(y_val, y_val_pred)\n",
    "    R2_val          = r2_score(y_val, y_val_pred)*100\n",
    "\n",
    "    y_test_pred     = model.predict(X_test)\n",
    "    RMSE_test       = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    MAE_test        = mean_absolute_error(y_test, y_test_pred)\n",
    "    R2_test         = r2_score(y_test, y_test_pred)*100\n",
    "\n",
    "    RMSE.append([RSME_train, RMSE_val, RMSE_test])\n",
    "    MAE.append([MAE_train, MAE_val, MAE_test])\n",
    "    R2.append([R2_train, R2_val, R2_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = pd.DataFrame(RMSE, columns=['RMSE Train','RMSE Validation','RMSE Test'])\n",
    "MAE = pd.DataFrame(MAE, columns=['MAE Train','MAE Validation','MAE Test'])\n",
    "R2 = pd.DataFrame(R2, columns=['R2 Train','R2 Validation','R2 Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_name = {\n",
    "    'Model' : [\n",
    "        'Swish: WnD',\n",
    "        'Swish: SQ',\n",
    "        'ReLU: WnD',\n",
    "        'ReLU: SQ',\n",
    "        'sigm: WnD',\n",
    "        'sigm: SQ',\n",
    "        'tanh: WnD',\n",
    "        'tanh: SQ'\n",
    "        ]}\n",
    "mod_name = pd.DataFrame(mod_name)\n",
    "result = pd.concat([mod_name,RMSE,MAE,R2], axis=1)\n",
    "result['Avg'] = (result['R2 Validation']+result['R2 Train'])/2\n",
    "result['Cons'] = result['Avg']-result['R2 Test']\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
