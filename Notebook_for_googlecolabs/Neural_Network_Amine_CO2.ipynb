{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing the required library\n",
    "!pip install tensorflow==2.10.0\n",
    "!pip install numpy==1.23.4\n",
    "!pip install pandas==1.5.2\n",
    "!pip install scikit-learn==1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing and visualizationlibrary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "# Tensorflow and keras library\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "# ScikitLearn library\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# Misc\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from unicodedata import name\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"To ensure repeatability, use the following setup:\")\n",
    "print(\"TensorFlow version:\", \"2.10.0\")\n",
    "print(\"Numpy version:\", '1.23.4')\n",
    "print(\"Pandas version:\", '1.5.2')\n",
    "print(\"SKLearn version:\", \"1.1.3\")\n",
    "print(\"Python version:\", \"3.8.6 (tags/v3.8.6:db45529, Sep 23 2020, 15:52:53) [MSC v.1927 64 bit (AMD64)]\")\n",
    "print(\"==============================\")\n",
    "print(\"Your current library version:\")\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"SKLearn version:\", sklearn.__version__)\n",
    "print(\"Python version:\",sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path1 = 'https://raw.githubusercontent.com/afriwahyudi/Supplementary/main/Notebook_for_LocalMachine/datasetscsv/trainval_set.csv' #Training-validation datasets\n",
    "csv_path2 = 'https://raw.githubusercontent.com/afriwahyudi/Supplementary/main/Notebook_for_LocalMachine/datasetscsv/test_set.csv' #Unseen test set\n",
    "csv_path3 = 'https://raw.githubusercontent.com/afriwahyudi/Supplementary/main/Notebook_for_LocalMachine/datasetscsv/master_dataset.csv' #Combined train-validation-test set\n",
    "csv_path4 = 'https://raw.githubusercontent.com/afriwahyudi/Supplementary/main/Notebook_for_LocalMachine/datasetscsv/allMolecule.csv' #Molecule only set\n",
    "\n",
    "# Setting up random seed for reproducibility\n",
    "seed = 21\n",
    "keras_seed = 21\n",
    "random.seed(seed) #This one is for python random seed\n",
    "tf.keras.utils.set_random_seed(keras_seed) #This one is for tensorflow random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "trainval_df = pd.read_csv(csv_path1, names=[\"Molecule\", \"Formula\",\"SMILES\",\"Type\",\"Cyclicity\",\n",
    "                                       \"Primary counts\",\"Secondary counts\",\"Tertiary counts\",\n",
    "                                       \"Hydroxyl counts\",\"Carboxyl counts\",\"Oxyl counts\",\n",
    "                                       \"M0(nhb)\", \"M0(oh)\", \"M0(nh)\", \"M0(op)\", \n",
    "                                       \"M1(nhb_donor)\", \"M1(nhb_weak)\", \"M1(nhb_acceptor)\",\n",
    "                                       \"M1(oh_donor)\", \"M1(oh_weak)\",\"M1(oh_acceptor)\",\n",
    "                                       \"M1(nh_donor)\", \"M1(nh_weak)\", \"M1(nh_acceptor)\",\n",
    "                                       \"M1(op_donor)\", \"M1(op_weak)\", \"M1(op_acceptor)\",\n",
    "                                       \"M2(nhb)\", \"M2(oh)\", \"M2(nh)\",\"M2(op)\",\n",
    "                                       \"MW\",\"Partial Pressure\",\"Temperature\",\n",
    "                                       \"Amine Concentration\", \"Absorption Capacity\", \"References\",\"Rounded Concentration\", \"Abbreviation\"]) \n",
    "test_df     = pd.read_csv(csv_path2, names=[\"Molecule\", \"Formula\",\"SMILES\",\"Type\",\"Cyclicity\", \n",
    "                                       \"Primary counts\",\"Secondary counts\",\"Tertiary counts\",\n",
    "                                       \"Hydroxyl counts\",\"Carboxyl counts\",\"Oxyl counts\",\n",
    "                                       \"M0(nhb)\", \"M0(oh)\", \"M0(nh)\", \"M0(op)\", \n",
    "                                       \"M1(nhb_donor)\", \"M1(nhb_weak)\", \"M1(nhb_acceptor)\",\n",
    "                                       \"M1(oh_donor)\", \"M1(oh_weak)\",\"M1(oh_acceptor)\",\n",
    "                                       \"M1(nh_donor)\", \"M1(nh_weak)\", \"M1(nh_acceptor)\",\n",
    "                                       \"M1(op_donor)\", \"M1(op_weak)\", \"M1(op_acceptor)\",\n",
    "                                       \"M2(nhb)\", \"M2(oh)\", \"M2(nh)\",\"M2(op)\",\n",
    "                                       \"MW\",\"Partial Pressure\",\"Temperature\",\n",
    "                                       \"Amine Concentration\", \"Absorption Capacity\", \"References\",\"Rounded Concentration\", \"Abbreviation\"]) \n",
    "# PREPROCESSING\n",
    "X_test_label = test_df.drop(columns=[\"Absorption Capacity\"])\n",
    "y_test = test_df['Absorption Capacity']\n",
    "\n",
    "X_trainval_label =  trainval_df.drop(columns=[\"Absorption Capacity\"])\n",
    "y_trainval_label = trainval_df['Absorption Capacity']\n",
    "\n",
    "# DATA SPLITING\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval_label, y_trainval_label, test_size=0.20, random_state=seed)\n",
    "\n",
    "# Reserve the dataset for visualization\n",
    "X_train_1 = X_train.copy()\n",
    "X_val_1 = X_val.copy()\n",
    "X_reserved = pd.concat([X_train_1, X_val_1, X_test_label], axis=0)\n",
    "\n",
    "# DROPPING STRINGS AND DATA PREPROCESSING\n",
    "X_train = X_train.drop(columns=[\"Molecule\", \"Formula\", \"SMILES\", \"Type\", \"Cyclicity\", \"References\", \"Rounded Concentration\", \"Abbreviation\"])\n",
    "X_test = X_test_label.drop(columns=[\"Molecule\", \"Formula\", \"SMILES\", \"Type\", \"Cyclicity\", \"References\", \"Rounded Concentration\", \"Abbreviation\"])\n",
    "X_val = X_val.drop(columns=[\"Molecule\", \"Formula\", \"SMILES\", \"Type\", \"Cyclicity\", \"References\", \"Rounded Concentration\", \"Abbreviation\"])\n",
    "\n",
    "feature_names = X_train.columns.tolist()\n",
    "preprocessor = Pipeline(steps=[('step1', StandardScaler())])\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=feature_names)\n",
    "\n",
    "X_val = pipeline.transform(X_val)\n",
    "X_val = pd.DataFrame(X_val, columns=feature_names)\n",
    "\n",
    "X_test = pipeline.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------CREATE MODEL------------------------------------------#\n",
    "tf.keras.backend.clear_session()\n",
    "# Neural Network Architecture\n",
    "input_features = keras.layers.Input(shape=X_train.shape[1], name='Input_Layer')\n",
    "hidden_layer_0 = keras.layers.Dense(units=100, activation='swish', name='Hidden_Layer_0', kernel_initializer = 'glorot_normal')(input_features)\n",
    "hidden_layer_0_bn = keras.layers.BatchNormalization()(hidden_layer_0) \n",
    "hidden_layer_1 = keras.layers.Dense(units=50, activation='swish', name='Hidden_Layer_1', kernel_initializer = 'glorot_normal')(hidden_layer_0_bn)\n",
    "hidden_layer_1_bn = keras.layers.BatchNormalization()(hidden_layer_1) \n",
    "concat = keras.layers.concatenate([input_features,hidden_layer_1_bn])\n",
    "output_layer = keras.layers.Dense(units=1,  activation='relu', name='Predicted_Loading', kernel_initializer = 'glorot_normal')(concat)\n",
    "model = keras.models.Model(inputs=[input_features], outputs=[output_layer])\n",
    "# create optimizer with custom learning rate\n",
    "optimizer = Adam(learning_rate=0.001, decay=0.00001)\n",
    "model.compile(loss='mae', optimizer=optimizer, metrics=['mse'])\n",
    "# Define TensorBoard log directory\n",
    "log_dir =   \"Model_\" + \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"ModelName\"\n",
    "# Create a TensorBoard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "# fit the model to the data\n",
    "cc_model = model.fit(X_train, y_train, validation_data=(X_val, y_val), \n",
    "                     epochs=5000, batch_size=32, verbose=0, callbacks=[tensorboard_callback, early_stopping])\n",
    "#-------------------------------------CREATE MODEL------------------------------------------#\n",
    "graph = keras.utils.plot_model(model, \"Architecture\"+\".png\", show_shapes=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving THE MODEL WITH DESIRED NAME\n",
    "model.save(\"ModelName.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(\"Train data RMSE: \", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Train data MAE: \", mean_absolute_error(y_train, y_train_pred))\n",
    "print(\"Train data R^2: \", r2_score(y_train, y_train_pred))\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "print(\"Validation data RMSE: \", np.sqrt(mean_squared_error(y_val, y_val_pred)))\n",
    "print(\"Validation data MAE: \", mean_absolute_error(y_val, y_val_pred))\n",
    "print(\"Validation data R^2: \", r2_score(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Test data RMSE: \", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"Test data MAE: \", mean_absolute_error(y_test, y_test_pred))\n",
    "print(\"Test data R^2: \", r2_score(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "dz_1 = X_train_1['Type']\n",
    "df_1 = pd.DataFrame(dz_1)\n",
    "\n",
    "dz_2 = X_test_label['Type']\n",
    "df_2 = pd.DataFrame(dz_2)\n",
    "\n",
    "dz_3 = X_val_1['Type']\n",
    "df_3 = pd.DataFrame(dz_3)\n",
    "x_vals = np.linspace(min(y_train), max(y_train), 100)\n",
    "\n",
    "# Assign a color to each categorical value (train_set)\n",
    "colors_1 = {'Primary': 'red', 'Secondary': 'green', 'Tertiary': 'blue', 'Polyamine': 'purple'}\n",
    "df_1['color'] = df_1['Type'].map(colors_1)\n",
    "\n",
    "# Assign a color to each categorical value (test_set)\n",
    "colors_2 = {'Primary': 'red', 'Secondary': 'green', 'Tertiary': 'blue', 'Polyamine': 'purple'}\n",
    "df_2['color'] = df_2['Type'].map(colors_2)\n",
    "\n",
    "# Assign a color to each categorical value (val_set)\n",
    "colors_3 = {'Primary': 'red', 'Secondary': 'green', 'Tertiary': 'blue', 'Polyamine': 'purple'}\n",
    "df_3['color'] = df_3['Type'].map(colors_3)\n",
    "\n",
    "# Plotting the predictions for the train set\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_train, y_train_pred, c=df_1['color'])\n",
    "plt.plot(x_vals, x_vals, color='black', linestyle='--')\n",
    "plt.title('Train Set Predictions')\n",
    "plt.xlabel(' True CO$_{2}$ Loading (mol$_{CO2}$/mol$_{A}$)')\n",
    "plt.ylabel(' Prediction CO$_{2}$ Loading (mol$_{CO2}$/mol$_{A}$)')\n",
    "legend_elements = [\n",
    "    matplotlib.patches.Patch(facecolor=color, label=label)\n",
    "    for label, color in colors_1.items()\n",
    "]\n",
    "plt.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# Plotting the predictions for the test set\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_test_pred, c=df_2['color'])\n",
    "plt.plot(x_vals, x_vals, color='black', linestyle='--')\n",
    "plt.title('Test Set Predictions')\n",
    "plt.xlabel(' True CO$_{2}$ Loading (mol$_{CO2}$/mol$_{A}$)')\n",
    "plt.ylabel(' Prediction CO$_{2}$ Loading (mol$_{CO2}$/mol$_{A}$)')\n",
    "legend_elements = [\n",
    "    matplotlib.patches.Patch(facecolor=color, label=label)\n",
    "    for label, color in colors_1.items()\n",
    "]\n",
    "plt.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# Plotting the predictions for the validation set\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_val, y_val_pred, c=df_3['color'])\n",
    "plt.plot(x_vals, x_vals, color='black', linestyle='--')\n",
    "plt.title('Validation Set Predictions')\n",
    "plt.xlabel(' True CO$_{2}$ Loading (mol$_{CO2}$/mol$_{A}$)')\n",
    "plt.ylabel(' Prediction CO$_{2}$ Loading (mol$_{CO2}$/mol$_{A}$)')\n",
    "legend_elements = [\n",
    "    matplotlib.patches.Patch(facecolor=color, label=label)\n",
    "    for label, color in colors_1.items()\n",
    "]\n",
    "plt.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=<log_dir>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
