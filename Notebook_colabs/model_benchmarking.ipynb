{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing the required library\n",
    "!pip install tensorflow==2.10.0\n",
    "!pip install numpy==1.23.4\n",
    "!pip install pandas==1.5.2\n",
    "!pip install scikit-learn==1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing and visualizationlibrary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "import seaborn as sns\n",
    "# Tensorflow and keras library\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "# ScikitLearn library\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Misc\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from unicodedata import name\n",
    "from datetime import datetime\n",
    "from scipy.optimize import root\n",
    "\n",
    "print(\"To ensure repeatability, use the following setup:\")\n",
    "print(\"TensorFlow version:\", \"2.10.0\")\n",
    "print(\"Numpy version:\", '1.23.4')\n",
    "print(\"Pandas version:\", '1.5.2')\n",
    "print(\"SKLearn version:\", \"1.1.3\")\n",
    "print(\"Python version:\", \"3.8.6 (tags/v3.8.6:db45529, Sep 23 2020, 15:52:53) [MSC v.1927 64 bit (AMD64)]\")\n",
    "print(\"==============================\")\n",
    "print(\"Your current library version:\")\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"SKLearn version:\", sklearn.__version__)\n",
    "print(\"Python version:\",sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset from GitHub repo\n",
    "csv_path1 = 'https://raw.githubusercontent.com/afriwahyudi/Supplementary/main/datasetscsv/trainval_set.csv' #Training-validation datasets\n",
    "csv_path2 = 'https://raw.githubusercontent.com/afriwahyudi/Supplementary/main/datasetscsv/test_set.csv' #Unseen test set\n",
    "csv_path3 = 'https://raw.githubusercontent.com/afriwahyudi/Supplementary/main/datasetscsv/trainval_set.csv' #Combined train-validation-test set\n",
    "csv_path4 = 'https://raw.githubusercontent.com/afriwahyudi/Supplementary/main/datasetscsv/2DMA2M1Ptest.csv' #2DMA2M1P test set from Zhang et al (2023)\n",
    "seed = 21\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model from GitHub repo in '/Model' folder\n",
    "!wget https://github.com/afriwahyudi/Supplementary/raw/main/Model/SWISH_WnD.h5\n",
    "model_path = 'SWISH_WnD.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing 2DMA2M1P testing set from Zhang et al (2023)\n",
    "df1 = pd.read_csv(csv_path4, names=[\"Molecule\", \"Formula\",\"SMILES\",\"Type\",\"Cyclicity\",\n",
    "                                       \"Primary counts\",\"Secondary counts\",\"Tertiary counts\",\n",
    "                                       \"Hydroxyl counts\",\"Carboxyl counts\",\"Oxyl counts\",\n",
    "                                       \"M0(nhb)\", \"M0(oh)\", \"M0(nh)\", \"M0(op)\", \n",
    "                                       \"M1(nhb_donor)\", \"M1(nhb_weak)\", \"M1(nhb_acceptor)\",\n",
    "                                       \"M1(oh_donor)\", \"M1(oh_weak)\",\"M1(oh_acceptor)\",\n",
    "                                       \"M1(nh_donor)\", \"M1(nh_weak)\", \"M1(nh_acceptor)\",\n",
    "                                       \"M1(op_donor)\", \"M1(op_weak)\", \"M1(op_acceptor)\",\n",
    "                                       \"M2(nhb)\", \"M2(oh)\", \"M2(nh)\",\"M2(op)\",\n",
    "                                       \"MW\",\"Partial Pressure\",\"Temperature\",\n",
    "                                       \"Amine Concentration\", \"Absorption Capacity\", \"References\",\"Rounded Concentration\", \"Abbreviation\"])\n",
    "\n",
    "screened = df1\n",
    "screened_input = screened.drop(columns=[\"Molecule\", \"Formula\",\"SMILES\",\"Type\",\"Cyclicity\",\n",
    "                                   \"Absorption Capacity\",\"References\",\"Rounded Concentration\", \"Abbreviation\"])\n",
    "actual_output = screened['Absorption Capacity']\n",
    "\n",
    "\n",
    "concpress = df1\n",
    "concpress = concpress[['Partial Pressure','Temperature', 'Rounded Concentration','Absorption Capacity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset for model datastructure\n",
    "trainval_df = pd.read_csv(csv_path1, names=[\"Molecule\", \"Formula\",\"SMILES\",\"Type\",\"Cyclicity\",\n",
    "                                       \"Primary counts\",\"Secondary counts\",\"Tertiary counts\",\n",
    "                                       \"Hydroxyl counts\",\"Carboxyl counts\",\"Oxyl counts\",\n",
    "                                       \"M0(nhb)\", \"M0(oh)\", \"M0(nh)\", \"M0(op)\", \n",
    "                                       \"M1(nhb_donor)\", \"M1(nhb_weak)\", \"M1(nhb_acceptor)\",\n",
    "                                       \"M1(oh_donor)\", \"M1(oh_weak)\",\"M1(oh_acceptor)\",\n",
    "                                       \"M1(nh_donor)\", \"M1(nh_weak)\", \"M1(nh_acceptor)\",\n",
    "                                       \"M1(op_donor)\", \"M1(op_weak)\", \"M1(op_acceptor)\",\n",
    "                                       \"M2(nhb)\", \"M2(oh)\", \"M2(nh)\",\"M2(op)\",\n",
    "                                       \"MW\",\"Partial Pressure\",\"Temperature\",\n",
    "                                       \"Amine Concentration\", \"Absorption Capacity\", \"References\",\"Rounded Concentration\", \"Abbreviation\"]) \n",
    "test_df     = pd.read_csv(csv_path2, names=[\"Molecule\", \"Formula\",\"SMILES\",\"Type\",\"Cyclicity\", \n",
    "                                       \"Primary counts\",\"Secondary counts\",\"Tertiary counts\",\n",
    "                                       \"Hydroxyl counts\",\"Carboxyl counts\",\"Oxyl counts\",\n",
    "                                       \"M0(nhb)\", \"M0(oh)\", \"M0(nh)\", \"M0(op)\", \n",
    "                                       \"M1(nhb_donor)\", \"M1(nhb_weak)\", \"M1(nhb_acceptor)\",\n",
    "                                       \"M1(oh_donor)\", \"M1(oh_weak)\",\"M1(oh_acceptor)\",\n",
    "                                       \"M1(nh_donor)\", \"M1(nh_weak)\", \"M1(nh_acceptor)\",\n",
    "                                       \"M1(op_donor)\", \"M1(op_weak)\", \"M1(op_acceptor)\",\n",
    "                                       \"M2(nhb)\", \"M2(oh)\", \"M2(nh)\",\"M2(op)\",\n",
    "                                       \"MW\",\"Partial Pressure\",\"Temperature\",\n",
    "                                       \"Amine Concentration\", \"Absorption Capacity\", \"References\",\"Rounded Concentration\", \"Abbreviation\"]) \n",
    "# PREPROCESSING\n",
    "X_test_label = test_df.drop(columns=[\"Absorption Capacity\"])\n",
    "y_test = test_df['Absorption Capacity']\n",
    "\n",
    "X_trainval_label =  trainval_df.drop(columns=[\"Absorption Capacity\"])\n",
    "y_trainval_label = trainval_df['Absorption Capacity']\n",
    "\n",
    "# DATA SPLITING\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval_label, y_trainval_label, test_size=0.20, random_state=seed)\n",
    "\n",
    "# Reserve the dataset for visualization\n",
    "X_train_1 = X_train.copy()\n",
    "X_val_1 = X_val.copy()\n",
    "X_reserved = pd.concat([X_train_1, X_val_1, X_test_label], axis=0)\n",
    "\n",
    "# DROPPING STRINGS AND DATA PREPROCESSING\n",
    "X_train = X_train.drop(columns=[\"Molecule\", \"Formula\", \"SMILES\", \"Type\", \"Cyclicity\", \"References\", \"Rounded Concentration\", \"Abbreviation\"])\n",
    "X_test = X_test_label.drop(columns=[\"Molecule\", \"Formula\", \"SMILES\", \"Type\", \"Cyclicity\", \"References\", \"Rounded Concentration\", \"Abbreviation\"])\n",
    "X_val = X_val.drop(columns=[\"Molecule\", \"Formula\", \"SMILES\", \"Type\", \"Cyclicity\", \"References\", \"Rounded Concentration\", \"Abbreviation\"])\n",
    "\n",
    "feature_names = X_train.columns.tolist()\n",
    "preprocessor = Pipeline(steps=[('step1', StandardScaler())])\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=feature_names)\n",
    "\n",
    "X_val = pipeline.transform(X_val)\n",
    "X_val = pd.DataFrame(X_val, columns=feature_names)\n",
    "\n",
    "X_test = pipeline.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=feature_names)\n",
    "\n",
    "#Overwriting dataset with master dataset\n",
    "master_df = pd.read_csv(csv_path3, \n",
    "    names=[\"Molecule\",\"Formula\",\"SMILES\",\"Type\",\"Cyclicity\",\n",
    "           \"Primary counts\",\"Secondary counts\",\"Tertiary counts\",\n",
    "           \"Hydroxyl counts\",\"Carboxyl counts\",\"Oxyl counts\",\n",
    "           \"M0(nhb)\", \"M0(oh)\", \"M0(nh)\", \"M0(op)\", \n",
    "           \"M1(nhb_donor)\", \"M1(nhb_weak)\", \"M1(nhb_acceptor)\",\n",
    "           \"M1(oh_donor)\", \"M1(oh_weak)\",\"M1(oh_acceptor)\",\n",
    "           \"M1(nh_donor)\", \"M1(nh_weak)\", \"M1(nh_acceptor)\",\n",
    "           \"M1(op_donor)\", \"M1(op_weak)\", \"M1(op_acceptor)\",\n",
    "           \"M2(nhb)\", \"M2(oh)\", \"M2(nh)\",\"M2(op)\",\n",
    "           \"MW\",\"Partial Pressure\",\"Temperature\",\n",
    "           \"Amine Concentration\", \"Absorption Capacity\", \"References\",\"Rounded Concentration\",\"Abbreviation\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WIDE-DEEP NN MODEL\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AAD DEFINITION\n",
    "def calculate_aad(y_exp, y_pred):\n",
    "    aad = 0\n",
    "    # Step 1: Compute the mean of the dataset\n",
    "    for i in range(len(y_exp)):\n",
    "        aad += sum(abs(y_exp.iloc[i]-y_pred.iloc[i])/y_exp.iloc[i])/len(y_exp)\n",
    "    return aad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KENT-EISENBERG MODEL\n",
    "    #EQUILIBRIUM CONSTANT AND HENRY\n",
    "def k1(T):\n",
    "    eqCons1 = np.exp((-17.1) + (-1550 / T) + (-400 / T**2) + (0.25 / T**3) + (0.05 / T**4))\n",
    "    return eqCons1\n",
    "def k3(T):\n",
    "    eqCons3 = np.exp((-241.818) + (298.253 * 10**3 / T) - (148.528 * 10**6 / T**2) + (332.648 * 10**8 / T**3) - (282.394 * 10**10 / T**4))\n",
    "    return eqCons3\n",
    "def k4(T):\n",
    "    eqCons4 = np.exp((-294.74) + (364.385 * 10**3 / T) - (184.158 * 10**6 / T**2) + (415.793 * 10**8 / T**3) - (354.291 * 10**10 / T**4))\n",
    "    return eqCons4\n",
    "def k5(T):\n",
    "    eqCons5 = np.exp((39.5554) - (987.9 * 10**2 / T) + (568.828 * 10**5 / T**2) - (146.456 * 10**8 / T**3) + (136.146 * 10**10 / T**4))\n",
    "    return eqCons5\n",
    "def h(T):\n",
    "    henCons = np.exp((22.2819) - (138.306 * 10**2 / T) + (691.346 * 10**4 / T**2) - (155.895 * 10**7 / T**3) + (120.037 * 10**9 / T**4)) / 7.50061\n",
    "    return henCons\n",
    "\n",
    "#EQUATION TO SOLVE H+\n",
    "def polynom(K1,K3,K4,K5,H,PCO2,Conc,ion):\n",
    "    A   = 1\n",
    "    B   = Conc+K1\n",
    "    C   = -K3*PCO2/H-K5\n",
    "    D   = -K1*K3* PCO2/H-K1*K5-2*K3*K4*PCO2/H\n",
    "    E   = -2*K1*K3*K4*PCO2/H\n",
    "    poleq = A*ion**4 + B*ion**3 + C*ion**2 + D*ion + E\n",
    "    return poleq\n",
    "\n",
    "#SOLVING CHARGE BALANCE\n",
    "PCO2 = concpress['Partial Pressure']\n",
    "Conc = concpress['Rounded Concentration']\n",
    "K1  = k1(concpress['Temperature'])\n",
    "K3  = k3(concpress['Temperature'])\n",
    "K4  = k4(concpress['Temperature'])\n",
    "K5  = k5(concpress['Temperature'])\n",
    "H   = h (concpress['Temperature'])\n",
    "\n",
    "# Define the function to find the root of\n",
    "def polynom_to_solve(ion):\n",
    "    return polynom(K1, K3, K4, K5, H, PCO2, Conc, ion)\n",
    "\n",
    "# Make an initial guess for the root\n",
    "initial_guess = np.ones(len(concpress)) * 1e-8\n",
    "\n",
    "# Find the root using scipy.optimize.root\n",
    "result = root(polynom_to_solve, initial_guess)\n",
    "\n",
    "# Check if the root was found successfully\n",
    "if result.success:\n",
    "    root_ion_values = result.x\n",
    "    print(\"Root found successfully.\")\n",
    "    #print(pd.DataFrame(-np.log10(root_ion_values), columns = ['pH']))\n",
    "else:\n",
    "    print(\"Root not found. Try a different initial guess or check your equations.\")\n",
    "alpha_pred_KE = PCO2/H/Conc*(1+K3/root_ion_values + K3*K4/root_ion_values**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HELEI-LIU MODEL\n",
    "    #EQUILIBRIUM CONSTANT AND HENRY\n",
    "def k1(T, Conc):\n",
    "    eqCons1 = np.exp((-29.10) + (0.0216*T) - (10.1300 / T) - (0.1750*np.log(Conc)))\n",
    "    return eqCons1\n",
    "def k3(T):\n",
    "    eqCons3 = np.exp((-241.818) + (298.253 * 10**3 / T) - (148.528 * 10**6 / T**2) + (332.648 * 10**8 / T**3) - (282.394 * 10**10 / T**4))\n",
    "    return eqCons3\n",
    "def k4(T):\n",
    "    eqCons4 = np.exp((-294.74) + (364.385 * 10**3 / T) - (184.158 * 10**6 / T**2) + (415.793 * 10**8 / T**3) - (354.291 * 10**10 / T**4))\n",
    "    return eqCons4\n",
    "def k5(T):\n",
    "    eqCons5 = np.exp((39.5554) - (987.9 * 10**2 / T) + (568.828 * 10**5 / T**2) - (146.456 * 10**8 / T**3) + (136.146 * 10**10 / T**4))\n",
    "    return eqCons5\n",
    "def h(T):\n",
    "    henCons = np.exp((22.2819) - (138.306 * 10**2 / T) + (691.346 * 10**4 / T**2) - (155.895 * 10**7 / T**3) + (120.037 * 10**9 / T**4)) / 7.50061\n",
    "    return henCons\n",
    "\n",
    "#EQUATION TO SOLVE H+\n",
    "def polynom(K1,K3,K4,K5,H,PCO2,Conc,ion):\n",
    "    A   = 1\n",
    "    B   = Conc+K1\n",
    "    C   = -K3*PCO2/H-K5\n",
    "    D   = -K1*K3* PCO2/H-K1*K5-2*K3*K4*PCO2/H\n",
    "    E   = -2*K1*K3*K4*PCO2/H\n",
    "    poleq = A*ion**4 + B*ion**3 + C*ion**2 + D*ion + E\n",
    "    return poleq\n",
    "\n",
    "#SOLVING CHARGE BALANCE\n",
    "PCO2 = concpress['Partial Pressure']\n",
    "Conc = concpress['Rounded Concentration']\n",
    "K1  = k1(concpress['Temperature'], Conc)\n",
    "K3  = k3(concpress['Temperature'])\n",
    "K4  = k4(concpress['Temperature'])\n",
    "K5  = k5(concpress['Temperature'])\n",
    "H   = h (concpress['Temperature'])\n",
    "\n",
    "# Define the function to find the root of\n",
    "def polynom_to_solve(ion):\n",
    "    return polynom(K1, K3, K4, K5, H, PCO2, Conc, ion)\n",
    "\n",
    "# Make an initial guess for the root\n",
    "initial_guess = np.ones(len(concpress)) * 1e-8\n",
    "\n",
    "# Find the root using scipy.optimize.root\n",
    "result = root(polynom_to_solve, initial_guess)\n",
    "\n",
    "# Check if the root was found successfully\n",
    "if result.success:\n",
    "    root_ion_values = result.x\n",
    "    print(\"Root found successfully.\")\n",
    "    #print(pd.DataFrame(-np.log10(root_ion_values), columns = ['pH']))\n",
    "else:\n",
    "    print(\"Root not found. Try a different initial guess or check your equations.\")\n",
    "alpha_pred_HL = PCO2/H/Conc*(1+K3/root_ion_values + K3*K4/root_ion_values**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cf MODEL\n",
    "    #EQUILIBRIUM CONSTANT AND HENRY\n",
    "\n",
    "def k1(T, Conc):\n",
    "    eqCons1 = np.exp((-29.10) + (0.0216*T) - (10.1300 / T) - (0.1750*np.log(Conc)))\n",
    "    return eqCons1\n",
    "def k3(T):\n",
    "    eqCons3 = np.exp((-241.818) + (298.253 * 10**3 / T) - (148.528 * 10**6 / T**2) + (332.648 * 10**8 / T**3) - (282.394 * 10**10 / T**4))\n",
    "    return eqCons3\n",
    "def k4(T):\n",
    "    eqCons4 = np.exp((-294.74) + (364.385 * 10**3 / T) - (184.158 * 10**6 / T**2) + (415.793 * 10**8 / T**3) - (354.291 * 10**10 / T**4))\n",
    "    return eqCons4\n",
    "def k5(T):\n",
    "    eqCons5 = np.exp((39.5554) - (987.9 * 10**2 / T) + (568.828 * 10**5 / T**2) - (146.456 * 10**8 / T**3) + (136.146 * 10**10 / T**4))\n",
    "    return eqCons5\n",
    "def h(T):\n",
    "    henCons = np.exp((22.2819) - (138.306 * 10**2 / T) + (691.346 * 10**4 / T**2) - (155.895 * 10**7 / T**3) + (120.037 * 10**9 / T**4)) / 7.50061\n",
    "    return henCons\n",
    "\n",
    "#EQUATION TO SOLVE H+\n",
    "def polynom(K1,K3,K4,K5,H,PCO2,Conc,ion):\n",
    "    A   = 1\n",
    "    B   = Conc+K1\n",
    "    C   = -K3*PCO2/H-K5\n",
    "    D   = -K1*K3* PCO2/H-K1*K5-2*K3*K4*PCO2/H\n",
    "    E   = -2*K1*K3*K4*PCO2/H\n",
    "    poleq = A*ion**4 + B*ion**3 + C*ion**2 + D*ion + E\n",
    "    return poleq\n",
    "\n",
    "#SOLVING CHARGE BALANCE\n",
    "PCO2 = concpress['Partial Pressure']\n",
    "Conc = concpress['Rounded Concentration']\n",
    "H   = h (concpress['Temperature'])\n",
    "K1  = k1(concpress['Temperature'], Conc)\n",
    "K3  = k3(concpress['Temperature'])\n",
    "K4  = k4(concpress['Temperature'])\n",
    "K5  = k5(concpress['Temperature'])\n",
    "\n",
    "\n",
    "# Define the function to find the root of\n",
    "def polynom_to_solve(ion):\n",
    "    return polynom(K1, K3, K4, K5, H, PCO2, Conc, ion)\n",
    "\n",
    "# Make an initial guess for the root\n",
    "initial_guess = np.ones(len(concpress)) * 1e-8\n",
    "\n",
    "# Find the root using scipy.optimize.root\n",
    "result = root(polynom_to_solve, initial_guess)\n",
    "\n",
    "# Check if the root was found successfully\n",
    "if result.success:\n",
    "    root_ion_values = result.x\n",
    "    print(\"Root found successfully.\")\n",
    "    #print(pd.DataFrame(-np.log10(root_ion_values), columns = ['pH']))\n",
    "else:\n",
    "    print(\"Root not found. Try a different initial guess or check your equations.\")\n",
    "\n",
    "dP = (max(PCO2)-min(PCO2))/(len(PCO2)-1)    \n",
    "extended_cf_model = (201.4/concpress['Temperature']) + (367.7/(PCO2 + dP)**4) - (97.93/(PCO2 + dP)**3) + (1.276/(PCO2 + dP)) - (0.0395*Conc) + (0.4022)\n",
    "\n",
    "root_ion_values = root_ion_values*extended_cf_model\n",
    "alpha_pred_Cf = PCO2/H/Conc*(1+K3/root_ion_values + K3*K4/root_ion_values**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL OUTPUT\n",
    "y_exp  = df1['Absorption Capacity']\n",
    "alpha_pred_KE = alpha_pred_KE\n",
    "alpha_pred_KE = pd.DataFrame(alpha_pred_KE, columns = ['Predicted loading'])\n",
    "\n",
    "alpha_pred_HL = alpha_pred_HL\n",
    "alpha_pred_HL = pd.DataFrame(alpha_pred_HL, columns = ['Predicted loading'])\n",
    "\n",
    "alpha_pred_Cf = alpha_pred_Cf\n",
    "alpha_pred_Cf = pd.DataFrame(alpha_pred_Cf, columns = ['Predicted loading'])\n",
    "\n",
    "alpha_pred_NN = model.predict(pipeline.transform(screened_input))\n",
    "alpha_pred_NN = pd.DataFrame(alpha_pred_NN, columns = ['Predicted loading'])\n",
    "#MODEL OUTPUT\n",
    "t1=round(calculate_aad(y_exp, alpha_pred_KE)*100, 1)\n",
    "t2=round(calculate_aad(y_exp, alpha_pred_HL)*100, 1)\n",
    "t3=round(calculate_aad(y_exp, alpha_pred_Cf)*100, 1)\n",
    "t4=round(calculate_aad(y_exp, alpha_pred_NN)*100, 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "fontsize = 15\n",
    "markersize = 50\n",
    "plt.scatter(y_exp,alpha_pred_KE, marker = '^', color='green', label = f\"Kent-Eisenberg Model ({t1}%)\", s = markersize)\n",
    "plt.plot(np.array([0,2]), np.array([0,2]), color = 'black')\n",
    "plt.xlabel('Experimental Loading',fontsize = fontsize)\n",
    "plt.ylabel('Predicted Loading',fontsize = fontsize)\n",
    "plt.xlim(0.4, 1)\n",
    "plt.ylim(0.4, 1)\n",
    "plt.xticks(np.arange(0.4, 1.3,step=0.2), fontsize = fontsize)\n",
    "plt.yticks(np.arange(0.4, 1.3,step=0.2), fontsize = fontsize)\n",
    "\n",
    "plt.scatter(y_exp,alpha_pred_HL, marker = 'o', color='blue', label = f\"Helei-Liu Model ({t2}%)\", s = markersize)\n",
    "plt.xlabel('Experimental Loading', fontsize = fontsize)\n",
    "plt.ylabel('Predicted Loading', fontsize = fontsize)\n",
    "plt.xlim(0.4, 1)\n",
    "plt.ylim(0.4, 1)\n",
    "plt.xticks(np.arange(0.4, 1.3,step=0.2), fontsize = fontsize)\n",
    "plt.yticks(np.arange(0.4, 1.3,step=0.2), fontsize = fontsize)\n",
    "\n",
    "plt.scatter(y_exp, alpha_pred_Cf, marker = 'x', color='purple', label = f\"Extended Cf Model ({t3}%)\", s = markersize)\n",
    "plt.xlabel('Experimental Loading', fontsize = fontsize)\n",
    "plt.ylabel('Predicted Loading', fontsize = fontsize)\n",
    "plt.xlim(0.4, 1)\n",
    "plt.ylim(0.4, 1)\n",
    "plt.xticks(np.arange(0.4, 1.3,step=0.2), fontsize = fontsize)\n",
    "plt.yticks(np.arange(0.4, 1.3,step=0.2), fontsize = fontsize)\n",
    "\n",
    "plt.scatter(y_exp,alpha_pred_NN, marker = 'v', color='red', label = f\"Wide and Deep NN ({t4}%)\", s = markersize)\n",
    "plt.xlabel('Experimental Loading', fontsize = fontsize)\n",
    "plt.ylabel('Predicted Loading', fontsize = fontsize)\n",
    "plt.xlim(0.4, 1)\n",
    "plt.ylim(0.4, 1)\n",
    "plt.xticks(np.arange(0.4, 1.3,step=0.2))\n",
    "plt.yticks(np.arange(0.4, 1.3,step=0.2))\n",
    "\n",
    "legend = plt.legend(fontsize=fontsize,frameon=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
