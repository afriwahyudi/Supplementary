{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing the required library\n",
    "!pip install tensorflow==2.10.0\n",
    "!pip install numpy==1.23.4\n",
    "!pip install pandas==1.5.2\n",
    "!pip install scikit-learn==1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing and visualization library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches\n",
    "import seaborn as sns\n",
    "# Tensorflow and keras library\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "# ScikitLearn library\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Misc\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from unicodedata import name\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "print(\"To ensure repeatability, use the following setup:\")\n",
    "print(\"TensorFlow version:\", \"2.10.0\")\n",
    "print(\"Numpy version:\", '1.23.4')\n",
    "print(\"Pandas version:\", '1.5.2')\n",
    "print(\"SKLearn version:\", \"1.1.3\")\n",
    "print(\"Python version:\", \"3.8.6 (tags/v3.8.6:db45529, Sep 23 2020, 15:52:53) [MSC v.1927 64 bit (AMD64)]\")\n",
    "print(\"==============================\")\n",
    "print(\"Your current library version:\")\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"SKLearn version:\", sklearn.__version__)\n",
    "print(\"Python version:\",sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset from GitHub repo\n",
    "csv_path1 = 'https://raw.githubusercontent.com/afriwahyudi/Supplementary/main/datasetscsv/trainval_set.csv' #Training-validation datasets\n",
    "csv_path2 = 'https://raw.githubusercontent.com/afriwahyudi/Supplementary/main/datasetscsv/test_set.csv' #Unseen test set\n",
    "csv_path3 = 'https://raw.githubusercontent.com/afriwahyudi/Supplementary/main/datasetscsv/trainval_set.csv' #Combined train-validation-test set\n",
    "csv_path4 = 'https://raw.githubusercontent.com/afriwahyudi/Supplementary/main/datasetscsv/allMolecule.csv' #Molecule only set\n",
    "seed = 21\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing model from GitHub repo in '/Model' folder\n",
    "!wget https://github.com/afriwahyudi/Supplementary/raw/main/Model/SWISH_WnD.h5\n",
    "model_path = 'SWISH_WnD.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset for model datastructure\n",
    "trainval_df = pd.read_csv(csv_path1, names=[\"Molecule\", \"Formula\",\"SMILES\",\"Type\",\"Cyclicity\",\n",
    "                                       \"Primary counts\",\"Secondary counts\",\"Tertiary counts\",\n",
    "                                       \"Hydroxyl counts\",\"Carboxyl counts\",\"Oxyl counts\",\n",
    "                                       \"M0(nhb)\", \"M0(oh)\", \"M0(nh)\", \"M0(op)\", \n",
    "                                       \"M1(nhb_donor)\", \"M1(nhb_weak)\", \"M1(nhb_acceptor)\",\n",
    "                                       \"M1(oh_donor)\", \"M1(oh_weak)\",\"M1(oh_acceptor)\",\n",
    "                                       \"M1(nh_donor)\", \"M1(nh_weak)\", \"M1(nh_acceptor)\",\n",
    "                                       \"M1(op_donor)\", \"M1(op_weak)\", \"M1(op_acceptor)\",\n",
    "                                       \"M2(nhb)\", \"M2(oh)\", \"M2(nh)\",\"M2(op)\",\n",
    "                                       \"MW\",\"Partial Pressure\",\"Temperature\",\n",
    "                                       \"Amine Concentration\", \"Absorption Capacity\", \"References\",\"Rounded Concentration\", \"Abbreviation\"]) \n",
    "test_df     = pd.read_csv(csv_path2, names=[\"Molecule\", \"Formula\",\"SMILES\",\"Type\",\"Cyclicity\", \n",
    "                                       \"Primary counts\",\"Secondary counts\",\"Tertiary counts\",\n",
    "                                       \"Hydroxyl counts\",\"Carboxyl counts\",\"Oxyl counts\",\n",
    "                                       \"M0(nhb)\", \"M0(oh)\", \"M0(nh)\", \"M0(op)\", \n",
    "                                       \"M1(nhb_donor)\", \"M1(nhb_weak)\", \"M1(nhb_acceptor)\",\n",
    "                                       \"M1(oh_donor)\", \"M1(oh_weak)\",\"M1(oh_acceptor)\",\n",
    "                                       \"M1(nh_donor)\", \"M1(nh_weak)\", \"M1(nh_acceptor)\",\n",
    "                                       \"M1(op_donor)\", \"M1(op_weak)\", \"M1(op_acceptor)\",\n",
    "                                       \"M2(nhb)\", \"M2(oh)\", \"M2(nh)\",\"M2(op)\",\n",
    "                                       \"MW\",\"Partial Pressure\",\"Temperature\",\n",
    "                                       \"Amine Concentration\", \"Absorption Capacity\", \"References\",\"Rounded Concentration\", \"Abbreviation\"]) \n",
    "# PREPROCESSING\n",
    "X_test_label = test_df.drop(columns=[\"Absorption Capacity\"])\n",
    "y_test = test_df['Absorption Capacity']\n",
    "\n",
    "X_trainval_label =  trainval_df.drop(columns=[\"Absorption Capacity\"])\n",
    "y_trainval_label = trainval_df['Absorption Capacity']\n",
    "\n",
    "# DATA SPLITING\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval_label, y_trainval_label, test_size=0.20, random_state=seed)\n",
    "\n",
    "# Reserve the dataset for visualization\n",
    "X_train_1 = X_train.copy()\n",
    "X_val_1 = X_val.copy()\n",
    "X_reserved = pd.concat([X_train_1, X_val_1, X_test_label], axis=0)\n",
    "\n",
    "# DROPPING STRINGS AND DATA PREPROCESSING\n",
    "X_train = X_train.drop(columns=[\"Molecule\", \"Formula\", \"SMILES\", \"Type\", \"Cyclicity\", \"References\", \"Rounded Concentration\", \"Abbreviation\"])\n",
    "X_test = X_test_label.drop(columns=[\"Molecule\", \"Formula\", \"SMILES\", \"Type\", \"Cyclicity\", \"References\", \"Rounded Concentration\", \"Abbreviation\"])\n",
    "X_val = X_val.drop(columns=[\"Molecule\", \"Formula\", \"SMILES\", \"Type\", \"Cyclicity\", \"References\", \"Rounded Concentration\", \"Abbreviation\"])\n",
    "\n",
    "feature_names = X_train.columns.tolist()\n",
    "preprocessor = Pipeline(steps=[('step1', StandardScaler())])\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=feature_names)\n",
    "\n",
    "X_val = pipeline.transform(X_val)\n",
    "X_val = pd.DataFrame(X_val, columns=feature_names)\n",
    "\n",
    "X_test = pipeline.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=feature_names)\n",
    "\n",
    "#Overwriting dataset with master dataset\n",
    "master_df = pd.read_csv(csv_path3, \n",
    "    names=[\"Molecule\",\"Formula\",\"SMILES\",\"Type\",\"Cyclicity\",\n",
    "           \"Primary counts\",\"Secondary counts\",\"Tertiary counts\",\n",
    "           \"Hydroxyl counts\",\"Carboxyl counts\",\"Oxyl counts\",\n",
    "           \"M0(nhb)\", \"M0(oh)\", \"M0(nh)\", \"M0(op)\", \n",
    "           \"M1(nhb_donor)\", \"M1(nhb_weak)\", \"M1(nhb_acceptor)\",\n",
    "           \"M1(oh_donor)\", \"M1(oh_weak)\",\"M1(oh_acceptor)\",\n",
    "           \"M1(nh_donor)\", \"M1(nh_weak)\", \"M1(nh_acceptor)\",\n",
    "           \"M1(op_donor)\", \"M1(op_weak)\", \"M1(op_acceptor)\",\n",
    "           \"M2(nhb)\", \"M2(oh)\", \"M2(nh)\",\"M2(op)\",\n",
    "           \"MW\",\"Partial Pressure\",\"Temperature\",\n",
    "           \"Amine Concentration\", \"Absorption Capacity\", \"References\",\"Rounded Concentration\",\"Abbreviation\"]) \n",
    "scaler = preprocessor.named_steps['step1']\n",
    "mean_values = scaler.mean_[27] # Mean partial pressure\n",
    "std_values = scaler.scale_[27] # STD partial pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on the test data\n",
    "model = load_model(model_path)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(\"Train data RMSE: \", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"Train data MAE: \", mean_absolute_error(y_train, y_train_pred))\n",
    "print(\"Train data R^2: \", r2_score(y_train, y_train_pred))\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "print(\"Validation data RMSE: \", np.sqrt(mean_squared_error(y_val, y_val_pred)))\n",
    "print(\"Validation data MAE: \", mean_absolute_error(y_val, y_val_pred))\n",
    "print(\"Validation data R^2: \", r2_score(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Test data RMSE: \", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"Test data MAE: \", mean_absolute_error(y_test, y_test_pred))\n",
    "print(\"Test data R^2: \", r2_score(y_test, y_test_pred))\n",
    "\n",
    "averaged_r_score = (r2_score(y_train, y_train_pred)+r2_score(y_test, y_test_pred)+r2_score(y_val, y_val_pred))/3\n",
    "#print(\"Averaged R^2: \", averaged_r_score)\n",
    "\n",
    "dz_1 = X_train_1['Type']\n",
    "df_1 = pd.DataFrame(dz_1)\n",
    "\n",
    "dz_2 = X_test_label['Type']\n",
    "df_2 = pd.DataFrame(dz_2)\n",
    "\n",
    "dz_3 = X_val_1['Type']\n",
    "df_3 = pd.DataFrame(dz_3)\n",
    "\n",
    "# Assign a color to each categorical value (train__set)\n",
    "colors_1 = {'Primary': 'red', 'Secondary': 'green', 'Tertiary': 'blue', 'Polyamine': 'purple'}\n",
    "df_1['color'] = df_1['Type'].map(colors_1)\n",
    "\n",
    "# Assign a color to each categorical value (train__set)\n",
    "colors_2 = {'Primary': 'red', 'Secondary': 'green', 'Tertiary': 'blue', 'Polyamine': 'purple'}\n",
    "df_2['color'] = df_2['Type'].map(colors_2)\n",
    "\n",
    "# Assign a color to each categorical value (train__set)\n",
    "colors_3 = {'Primary': 'red', 'Secondary': 'green', 'Tertiary': 'blue', 'Polyamine': 'purple'}\n",
    "df_3['color'] = df_3['Type'].map(colors_3)\n",
    "\n",
    "#Visualize predictions for train, test, and validation data\n",
    "x_vals = np.linspace(min(y_train), max(y_train), 100)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_train, y_train_pred, c=df_1['color'])\n",
    "plt.scatter(y_test, y_test_pred, c=df_2['color'])\n",
    "plt.scatter(y_val, y_val_pred, c=df_3['color'])\n",
    "plt.plot(x_vals, x_vals, color='black', linestyle='--')\n",
    "plt.xlabel(' True CO$_{2}$ Loading (mol$_{CO2}$/mol$_{A}$)')\n",
    "plt.ylabel(' Prediction CO$_{2}$ Loading (mol$_{CO2}$/mol$_{A}$)')\n",
    "legend_elements = [\n",
    "    matplotlib.patches.Patch(facecolor=color, label=label)\n",
    "    for label, color in colors_1.items()\n",
    "]\n",
    "plt.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# Plotting the predictions for the train set\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_train, y_train_pred, c=df_1['color'])\n",
    "plt.plot(x_vals, x_vals, color='black', linestyle='--')\n",
    "plt.title('Train Set Predictions')\n",
    "plt.xlabel(' True CO$_{2}$ Loading (mol$_{CO2}$/mol$_{A}$)')\n",
    "plt.ylabel(' Prediction CO$_{2}$ Loading (mol$_{CO2}$/mol$_{A}$)')\n",
    "legend_elements = [\n",
    "    matplotlib.patches.Patch(facecolor=color, label=label)\n",
    "    for label, color in colors_1.items()\n",
    "]\n",
    "plt.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.show()\n",
    "# Plotting the predictions for the validation set\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_val, y_val_pred, c=df_3['color'])\n",
    "plt.plot(x_vals, x_vals, color='black', linestyle='--')\n",
    "plt.title('Validation Set Predictions')\n",
    "plt.xlabel(' True CO$_{2}$ Loading (mol$_{CO2}$/mol$_{A}$)')\n",
    "plt.ylabel(' Prediction CO$_{2}$ Loading (mol$_{CO2}$/mol$_{A}$)')\n",
    "legend_elements = [\n",
    "    matplotlib.patches.Patch(facecolor=color, label=label)\n",
    "    for label, color in colors_1.items()\n",
    "]\n",
    "plt.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.show()\n",
    "# Plotting the predictions for the test set\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_test_pred, c=df_2['color'])\n",
    "plt.plot(x_vals, x_vals, color='black', linestyle='--')\n",
    "plt.title('Test Set Predictions')\n",
    "plt.xlabel(' True CO$_{2}$ Loading (mol$_{CO2}$/mol$_{A}$)')\n",
    "plt.ylabel(' Prediction CO$_{2}$ Loading (mol$_{CO2}$/mol$_{A}$)')\n",
    "legend_elements = [\n",
    "    matplotlib.patches.Patch(facecolor=color, label=label)\n",
    "    for label, color in colors_1.items()\n",
    "]\n",
    "plt.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Molecule_var      = master_df.drop(columns='Absorption Capacity')\n",
    "Molecule_var      = Molecule_var.drop_duplicates(subset = 'Molecule')\n",
    "Molecule_var      = Molecule_var.reset_index(drop=True)\n",
    "#Assigning index for each molecule\n",
    "Molecule_id       = Molecule_var.drop(columns= [\"M0(nhb)\", \"M0(oh)\", \"M0(nh)\", \"M0(op)\", \n",
    "                                                \"M1(nhb_donor)\", \"M1(nhb_weak)\", \"M1(nhb_acceptor)\",\n",
    "                                                \"M1(oh_donor)\", \"M1(oh_weak)\",\"M1(oh_acceptor)\",\n",
    "                                                \"M1(nh_donor)\", \"M1(nh_weak)\", \"M1(nh_acceptor)\",\n",
    "                                                \"M1(op_donor)\", \"M1(op_weak)\", \"M1(op_acceptor)\",\n",
    "                                                \"M2(nhb)\", \"M2(oh)\", \"M2(nh)\",\"M2(op)\",\n",
    "                                                \"MW\",\"Partial Pressure\",\"Temperature\",\n",
    "                                                \"Formula\",\"SMILES\",\"Type\",\"Cyclicity\",\n",
    "                                                \"Primary counts\",\"Secondary counts\",\"Tertiary counts\",\n",
    "                                                \"Hydroxyl counts\",\"Carboxyl counts\",\"Oxyl counts\",\n",
    "                                                \"Amine Concentration\",\"References\",\"Rounded Concentration\"])\n",
    "Molecule_id       = Molecule_id.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining constant operating condition to analyse\n",
    "size = 1\n",
    "fold = 1\n",
    "T_ref = 303.15\n",
    "T_tar = 313.15\n",
    "percent_vol_CO2 = 0.15\n",
    "Part_pres = 100\n",
    "PCO2                       = np.ones(size)*Part_pres # PARTIAL PRESSURE IN kPa\n",
    "T                          = np.ones(size)*T_tar # TEMPERATURE IN KELVIN'\n",
    "C                          = np.ones(size)*3  #CONCENTRATION IN MOLAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_alpha = []\n",
    "for i in range(len(Molecule_id)):\n",
    "    species = i\n",
    "    # Create Prediction Set\n",
    "    Prediction_set= pd.DataFrame(data={\n",
    "                #DESCRIPTOR\n",
    "                'Primary counts'                   : np.ones(size)*Molecule_var.iloc[species]['Primary counts'],\n",
    "                'Secondary counts'                 : np.ones(size)*Molecule_var.iloc[species]['Secondary counts'],\n",
    "                'Tertiary counts'                  : np.ones(size)*Molecule_var.iloc[species]['Tertiary counts'],\n",
    "                'Hydroxyl counts'                  : np.ones(size)*Molecule_var.iloc[species]['Hydroxyl counts'],\n",
    "                'Carboxyl counts'                  : np.ones(size)*Molecule_var.iloc[species]['Carboxyl counts'],\n",
    "                'Oxyl counts'                      : np.ones(size)*Molecule_var.iloc[species]['Oxyl counts'],\n",
    "                'M0(nhb)'                          : np.ones(size)*Molecule_var.iloc[species]['M0(nhb)'],\n",
    "                'M0(oh)'                           : np.ones(size)*Molecule_var.iloc[species]['M0(oh)'],\n",
    "                'M0(nh)'                           : np.ones(size)*Molecule_var.iloc[species]['M0(nh)'],\n",
    "                'M0(op)'                           : np.ones(size)*Molecule_var.iloc[species]['M0(op)'],\n",
    "                'M1(nhb_donor)'                    : np.ones(size)*Molecule_var.iloc[species]['M1(nhb_donor)'],\n",
    "                'M1(nhb_weak)'                     : np.ones(size)*Molecule_var.iloc[species]['M1(nhb_weak)'],\n",
    "                'M1(nhb_acceptor)'                 : np.ones(size)*Molecule_var.iloc[species]['M1(nhb_acceptor)'],\n",
    "                'M1(oh_donor)'                     : np.ones(size)*Molecule_var.iloc[species]['M1(oh_donor)'],\n",
    "                'M1(oh_weak)'                      : np.ones(size)*Molecule_var.iloc[species]['M1(oh_weak)'],\n",
    "                'M1(oh_acceptor)'                  : np.ones(size)*Molecule_var.iloc[species]['M1(oh_acceptor)'],\n",
    "                'M1(nh_donor)'                     : np.ones(size)*Molecule_var.iloc[species]['M1(nh_donor)'],\n",
    "                'M1(nh_weak)'                      : np.ones(size)*Molecule_var.iloc[species]['M1(nh_weak)'],\n",
    "                'M1(nh_acceptor)'                  : np.ones(size)*Molecule_var.iloc[species]['M1(nh_acceptor)'],\n",
    "                'M1(op_donor)'                     : np.ones(size)*Molecule_var.iloc[species]['M1(op_donor)'],\n",
    "                'M1(op_weak)'                      : np.ones(size)*Molecule_var.iloc[species]['M1(op_weak)'],\n",
    "                'M1(op_acceptor)'                  : np.ones(size)*Molecule_var.iloc[species]['M1(op_acceptor)'],\n",
    "                'M2(nhb)'                          : np.ones(size)*Molecule_var.iloc[species]['M2(nhb)'],\n",
    "                'M2(oh)'                           : np.ones(size)*Molecule_var.iloc[species]['M2(oh)'],                \n",
    "                'M2(nh)'                           : np.ones(size)*Molecule_var.iloc[species]['M2(nh)'],\n",
    "                'M2(op)'                           : np.ones(size)*Molecule_var.iloc[species]['M2(op)'],\n",
    "                'MW'                               : np.ones(size)*Molecule_var.iloc[species]['MW'],\n",
    "                #OPERATING CONDITION\n",
    "                'Partial Pressure'                 : PCO2, #x axis in 3d plot\n",
    "                'Temperature'                      : T, #y axis in 3d plot\n",
    "                'Amine Concentration'              : C            \n",
    "                })\n",
    "\n",
    "    Prediction_set_new = pipeline.transform(Prediction_set)\n",
    "    column_names = Prediction_set.columns.tolist()\n",
    "    Prediction_set_new = pd.DataFrame(Prediction_set_new, columns=column_names)\n",
    "\n",
    "    #Prediction\n",
    "    z_pred = model.predict(Prediction_set_new, verbose=0)\n",
    "    pred_alpha.append(z_pred)\n",
    "pred_alpha_reshaped = np.array(pred_alpha).reshape(len(Molecule_id), 1)\n",
    "pr_load = pd.DataFrame(pred_alpha_reshaped,columns=['Predicted loading'])\n",
    "result = pd.concat([Molecule_var['Molecule'],Molecule_var['Type'],Molecule_var['Abbreviation'] ,pr_load], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining variable for molecule analysis\n",
    "itv = 3 #Temperature interval\n",
    "selected = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating dH\n",
    "size = 1\n",
    "stored_P_each = []\n",
    "stored_dH = []\n",
    "stored_name = []\n",
    "stored_cap = []\n",
    "stored_Ntype = []\n",
    "for k in range(len(selected)):\n",
    "    start_time_inner = time.time()\n",
    "    name = selected.iloc[k]['Abbreviation']\n",
    "    Ntype = selected.iloc[k]['Type']\n",
    "    stored_Ntype.append(Ntype)\n",
    "    sel_mol = Molecule_id[Molecule_id['Abbreviation'] == name]\n",
    "    sel_mol_index = sel_mol.index[0]\n",
    "    species = sel_mol_index\n",
    "    stored_name.append(sel_mol)\n",
    "    abs_int = selected.iloc[k]['Predicted loading']\n",
    "    desired_absorption_capacity = abs_int\n",
    "    stored_cap.append(desired_absorption_capacity)\n",
    "    stored_P  = []\n",
    "    interval_T = np.linspace(T_ref, T_tar,itv)\n",
    "    PCO2 = np.ones(size)*0\n",
    "    for i in range(len(interval_T)):\n",
    "        # Create Prediction Set\n",
    "        Prediction_set= pd.DataFrame(data={\n",
    "                    #DESCRIPTOR\n",
    "                    'Primary counts'                   : np.ones(size)*Molecule_var.iloc[species]['Primary counts'],\n",
    "                    'Secondary counts'                 : np.ones(size)*Molecule_var.iloc[species]['Secondary counts'],\n",
    "                    'Tertiary counts'                  : np.ones(size)*Molecule_var.iloc[species]['Tertiary counts'],\n",
    "                    'Hydroxyl counts'                  : np.ones(size)*Molecule_var.iloc[species]['Hydroxyl counts'],\n",
    "                    'Carboxyl counts'                  : np.ones(size)*Molecule_var.iloc[species]['Carboxyl counts'],\n",
    "                    'Oxyl counts'                      : np.ones(size)*Molecule_var.iloc[species]['Oxyl counts'],\n",
    "                    'M0(nhb)'                          : np.ones(size)*Molecule_var.iloc[species]['M0(nhb)'],\n",
    "                    'M0(oh)'                           : np.ones(size)*Molecule_var.iloc[species]['M0(oh)'],\n",
    "                    'M0(nh)'                           : np.ones(size)*Molecule_var.iloc[species]['M0(nh)'],\n",
    "                    'M0(op)'                           : np.ones(size)*Molecule_var.iloc[species]['M0(op)'],\n",
    "                    'M1(nhb_donor)'                    : np.ones(size)*Molecule_var.iloc[species]['M1(nhb_donor)'],\n",
    "                    'M1(nhb_weak)'                     : np.ones(size)*Molecule_var.iloc[species]['M1(nhb_weak)'],\n",
    "                    'M1(nhb_acceptor)'                 : np.ones(size)*Molecule_var.iloc[species]['M1(nhb_acceptor)'],\n",
    "                    'M1(oh_donor)'                     : np.ones(size)*Molecule_var.iloc[species]['M1(oh_donor)'],\n",
    "                    'M1(oh_weak)'                      : np.ones(size)*Molecule_var.iloc[species]['M1(oh_weak)'],\n",
    "                    'M1(oh_acceptor)'                  : np.ones(size)*Molecule_var.iloc[species]['M1(oh_acceptor)'],\n",
    "                    'M1(nh_donor)'                     : np.ones(size)*Molecule_var.iloc[species]['M1(nh_donor)'],\n",
    "                    'M1(nh_weak)'                      : np.ones(size)*Molecule_var.iloc[species]['M1(nh_weak)'],\n",
    "                    'M1(nh_acceptor)'                  : np.ones(size)*Molecule_var.iloc[species]['M1(nh_acceptor)'],\n",
    "                    'M1(op_donor)'                     : np.ones(size)*Molecule_var.iloc[species]['M1(op_donor)'],\n",
    "                    'M1(op_weak)'                      : np.ones(size)*Molecule_var.iloc[species]['M1(op_weak)'],\n",
    "                    'M1(op_acceptor)'                  : np.ones(size)*Molecule_var.iloc[species]['M1(op_acceptor)'],\n",
    "                    'M2(nhb)'                          : np.ones(size)*Molecule_var.iloc[species]['M2(nhb)'],\n",
    "                    'M2(oh)'                           : np.ones(size)*Molecule_var.iloc[species]['M2(oh)'],                \n",
    "                    'M2(nh)'                           : np.ones(size)*Molecule_var.iloc[species]['M2(nh)'],\n",
    "                    'M2(op)'                           : np.ones(size)*Molecule_var.iloc[species]['M2(op)'],\n",
    "                    'MW'                               : np.ones(size)*Molecule_var.iloc[species]['MW'],\n",
    "                    #OPERATING CONDITION\n",
    "                    'Partial Pressure'                 : PCO2, #x axis in 3d plot\n",
    "                    'Temperature'                      : interval_T[i], #y axis in 3d plot\n",
    "                    'Amine Concentration'              : C            \n",
    "                    })\n",
    "        Prediction_set_new = pipeline.transform(Prediction_set)\n",
    "        column_names = Prediction_set.columns.tolist()\n",
    "        Prediction_set_new = pd.DataFrame(Prediction_set_new, columns=column_names)\n",
    "        def loss_function(y_true, y_pred):\n",
    "            return abs(y_true - y_pred)\n",
    "        predicted_absorption_capacity = model.predict(Prediction_set_new, verbose=1)\n",
    "        lower_bound = (min(X_train_1['Partial Pressure']) - mean_values)/std_values\n",
    "        upper_bound = (max(X_train_1['Partial Pressure']) - mean_values)/std_values\n",
    "        tolerance = 0.00001\n",
    "        max_iterations = 1000\n",
    "\n",
    "        for _ in range(max_iterations):\n",
    "            current_partial_pressure = (lower_bound + upper_bound) / 2\n",
    "            input_with_desired_absorption_capacity = Prediction_set_new.copy()\n",
    "            input_with_desired_absorption_capacity['Partial Pressure'] = current_partial_pressure\n",
    "            \n",
    "            # Use the transformed input to make predictions\n",
    "            predicted_absorption_capacity_inverse = model.predict(input_with_desired_absorption_capacity, verbose=0)\n",
    "            \n",
    "            loss = loss_function(desired_absorption_capacity, predicted_absorption_capacity_inverse)\n",
    "            \n",
    "            if loss < tolerance:\n",
    "                break\n",
    "            elif predicted_absorption_capacity_inverse < desired_absorption_capacity:\n",
    "                lower_bound = current_partial_pressure\n",
    "            else:\n",
    "                upper_bound = current_partial_pressure\n",
    "        optimal_partial_pressure = current_partial_pressure\n",
    "        optimal_partial_pressure = round(optimal_partial_pressure*std_values + mean_values, 3)\n",
    "        stored_P.append(optimal_partial_pressure)     \n",
    "    stored_P_each.append(stored_P)\n",
    "    time_taken = time.time() - start_time_inner\n",
    "    print(name, f\"Iteration {k + 1} took {time_taken:.5f} seconds\")\n",
    "for m in range(len(stored_P_each)):\n",
    "    Xs = pd.DataFrame(1/interval_T, columns = ['1/T'])\n",
    "    ys = pd.DataFrame(np.log(stored_P_each[m]), columns = ['lnP'])\n",
    "    met = LinearRegression()\n",
    "    findslope = met.fit(Xs, ys)\n",
    "    heat = met.coef_[0]*8.314/1000\n",
    "    stored_dH.append(heat)\n",
    "dH_pred_reshape = np.array(stored_dH).reshape(len(stored_P_each), 1)\n",
    "dH_pred_reshape = pd.DataFrame(dH_pred_reshape, columns=['dH_abs'])\n",
    "name_reshape = np.array(stored_name).reshape(len(selected), 2)\n",
    "name_reshape = pd.DataFrame(name_reshape, columns=['Molecule','Abbreviation'])\n",
    "\n",
    "Ntype_reshape = np.array(stored_Ntype).reshape(len(selected), 1)\n",
    "Ntype_reshape = pd.DataFrame(Ntype_reshape, columns=['Type'])\n",
    "\n",
    "stored_cap_reshape = np.array(stored_cap).reshape(len(selected), 1)\n",
    "stored_cap_reshape = pd.DataFrame(stored_cap_reshape, columns=['Equilibrium alpha'])\n",
    "\n",
    "Results = pd.concat([name_reshape,Ntype_reshape,stored_cap_reshape,dH_pred_reshape], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 15\n",
    "markersize = 40\n",
    "x = Results['dH_abs']  # Extracting the 'dH_abs' column as x-axis data\n",
    "y = Results['Equilibrium alpha']  # Extracting the 'Equilibrium alpha' column as y-axis data\n",
    "names = Results['Abbreviation']  # Extracting the 'Molecule' column for annotations\n",
    "\n",
    "type_to_color = {\n",
    "    'Primary': 'red',\n",
    "    'Secondary': 'green',\n",
    "    'Tertiary': 'blue',\n",
    "    'Polyamine': 'purple'\n",
    "}\n",
    "\n",
    "# Generating an array of colors for each data point\n",
    "colors = [type_to_color[type_] for type_ in Results['Type']]\n",
    "plt.figure(figsize=(11, 7))\n",
    "plt.scatter(x, y, c=colors, s = markersize)  # 'cmap' specifies the colormap to use for coloring points\n",
    "# Adding annotations for each data point\n",
    "annotations = [plt.annotate(name, (x[i], y[i]), textcoords=\"offset points\", xytext=(5,5),\n",
    "                           ha='center', fontsize=fontsize-4)\n",
    "               for i, name in enumerate(names)]\n",
    "\n",
    "plt.xlabel(r'$\\Delta H_{\\mathrm{abs}}$ (kJ/mol)',fontsize = fontsize)\n",
    "plt.ylabel('CO$_{2}$ Loading (mol$_{CO2}$/mol$_{A}$)', fontsize = fontsize)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
